{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Curse of Dimensionality\n",
    "\n",
    "From the book A Geron. Let's dive in what he is trying to explain\n",
    "\n",
    "Many Machine Learning problems involve thousands or even millions of features for each training\n",
    "instance. Not only does this make training extremely slow, it can also make it much harder to find a good\n",
    "solution, as we will see. This problem is often referred to as the curse of dimensionality.\n",
    "\n",
    "Yes, it speed up the training, but it also helps in data visualization. Ploting data in 2D instead.\n",
    "\n",
    "### Some tips\n",
    "Always start training with no dimension reduction. It may damage your training. since you are taking some might be relevant information out.\n",
    "\n",
    "All training instances actually lie within (or close to) a much lower-dimensional subspace of the\n",
    "high-dimensional space. To see this, we can **project** data points on two dim axes and see how well they are represented.\n",
    "\n",
    "### Three type of dimension reduction (most popular)\n",
    "PCA, Kernel PCA, and LLE\n",
    "\n",
    "### PCA\n",
    "Principal Component Analysis (PCA) is by far the most popular dimensionality reduction algorithm.\n",
    "First it identifies the hyperplane that lies closest to the data, and then it projects the data onto it.\n",
    "In meaning that the variance of a given feature represent the information that it contain. The PCA method tends to minimize the loss of the variance by projecting original features on their most closest hyperplane.\n",
    "\n",
    "there is a standard matrix factorization technique called Singular Value Decomposition (SVD) that can decompose the training set\n",
    "matrix X into the dot product of three matrices U · Σ · VT, where VT contains all the principal components\n",
    "that we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.04775913],\n",
       "       [ 0.04775913,  1.        ]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# let's create X\n",
    "X=np.random.randn(10,10)\n",
    "y=np.random.randn(10,1)\n",
    "X_centered = X - X.mean(axis=0)                # let's center variables first\n",
    "U, s, V = np.linalg.svd(X_centered)            # Now we can use SVD to construct the correlation matrix\n",
    "c1 = V.T[:, 0] \n",
    "c2 = V.T[:, 1]\n",
    "np.corrcoef(c1,c2) # we can show that c1 and c2 are not correlated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA assumes that the dataset is centered around the origin. As we will see, **Scikit-Learn**’s PCA classes take care of centering the data for you. However, if you implement PCA yourself (as in the preceding example), or if you use other libraries, don’t forget to **center** the data first.\n",
    "\n",
    "Here let's project the training set onto the plane defined by the first two principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W2 = V.T[:, :2]\n",
    "X2D = X_centered.dot(W2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIEiSGgNBkgQYCJKk5v8D8eSKwo6wOfgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127f1828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X2D[:,0], X2D[:,1])\n",
    "plt.title('Features on 2 PCA components')\n",
    "plt.ylabel('C1')\n",
    "plt.xlabel('C2')\n",
    "plt.savefig('PCA.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Scikit-Learn\n",
    "Scikit-Learn’s PCA class implements PCA using **SVD** decomposition just like we did before. The\n",
    "following code applies PCA to reduce the dimensionality of the dataset down to two dimensions (note\n",
    "that it **automatically takes care of centering the data**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 3) # choose the number of component to keep\n",
    "#X2D0 = pca.fit_transform(X)\n",
    "# pca.components_.T[:, 0] # not working \n",
    "# print(pca.explained_variance_ratio_) # the explained variance ratios of the first two components of the 3D dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to choose the right number PC.\n",
    "You can still do the decompose above and then compute cumsum to see if your explained information amount is met.\n",
    "\n",
    "The following code computes PCA without reducing dimensionality, then computes the minimum number\n",
    "of dimensions required to preserve 95% of the training set’s variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39737359,  0.60848519,  0.75978331,  0.8630683 ,  0.93588576,\n",
       "        0.96423609,  0.98624802,  0.99950901,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "d\n",
    "cumsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could then set **n_components**=d and run PCA again.\n",
    "However, there is a much better option: instead of specifying the number of principal components you want to preserve, you can set **n_components** to be a **float between 0.0 and 1.0**, indicating the **ratio of variance** you wish to preserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "#pca = PCA(n_components=d)\n",
    "X_reduced = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to **decompress** the reduced a dataset back to its original dimensions by applying the **inverse\n",
    "transformation** of the PCA projection. Of course this won’t give you back the original data, since the **projection** lost a bit of information (within the 5% variance that was dropped), but it will likely be quite close to the original data. The mean squared distance between the original data and the reconstructed data (compressed and then decompressed) is called the **reconstruction error**\n",
    "\n",
    "An example below with the compression of MNIST data from 784 to 150 to keep 95% of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's start by fetching the data\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X_mnist=mnist.data\n",
    "#X_mnist.target.shape\n",
    "#np.unique(mnist.target).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 154)\n",
    "X_mnist_reduced = pca.fit_transform(X_mnist)\n",
    "X_mnist_recovered = pca.inverse_transform(X_mnist_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new PCA associated data of MNIST's shape is : (70000, 154)\n",
      "The Recovered back data of MNIST  shape is : (70000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"The new PCA associated data of MNIST's shape is : \" +  str(X_mnist_reduced.shape))\n",
    "print(\"The Recovered back data of MNIST  shape is : \" +  str(X_mnist_recovered.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Incremental PCA** for large Data Set or online/ Streaming data dimension reduction.\n",
    "We do it through **mini-batches** : you can split the training set into mini-batches and feed an IPCA algorithm one minibatch\n",
    "at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code splits the MNIST dataset into 100 mini-batches (using NumPy’s array_split()\n",
    "function) and feeds them to Scikit-Learn’s IncrementalPCA class5 to reduce the dimensionality of the\n",
    "MNIST dataset down to 154 dimensions (just like before). Note that you must call the **partial_fit()**\n",
    "method with each **mini-batch** rather than the **fit()** method with the whole training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "n_batches = 100\n",
    "inc_pca = IncrementalPCA(n_components=154)\n",
    "for X_batch in np.array_split(X_mnist, n_batches):\n",
    "    inc_pca.partial_fit(X_batch)\n",
    "    X_mnist_reduced = inc_pca.transform(X_mnist)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 154)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mnist_reduced.s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the numpy memmap help us to use **fit()** . This module helps use disk binary data as if they were in memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_mm = np.memmap(X_mnist, dtype=\"float32\", mode=\"readonly\", shape=)\n",
    "batch_size = 100 // n_batches\n",
    "inc_pca = IncrementalPCA(n_components=154, batch_size=batch_size)\n",
    "inc_pca.fit(X_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomized PCA**\n",
    "Scikit-Learn offers yet another option to perform PCA, called Randomized PCA. This is a stochastic algorithm that quickly finds an approximation of the first d principal components. Its computational complexity is O(m × d2) + O(d3), instead of O(m × n2) + O(n3), so it is dramatically faster than the previous algorithms when d is much smaller than n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kbalde\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:52: DeprecationWarning: Class RandomizedPCA is deprecated; RandomizedPCA was deprecated in 0.18 and will be removed in 0.20. Use PCA(svd_solver='randomized') instead. The new implementation DOES NOT store whiten ``components_``. Apply transform to get them.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import RandomizedPCA \n",
    "rnd_pca = RandomizedPCA(n_components=154)\n",
    "X_reduced = rnd_pca.fit_transform(X_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel PCA\n",
    "\n",
    "We use Kernel Tricks to decrease the dimension. It means like in SVM, using high dim poly without really implementing them. making it possible to perform complex nonlinear projections for dimensionality reduction. This is called **Kernel PCA (kPCA)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.04)\n",
    "X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Kernel and Tuning Hyperparameters\n",
    "As kPCA is an unsupervised learning algorithm, there is no obvious performance measure to help you\n",
    "select the best kernel and hyperparameter values. However, dimensionality reduction is often a\n",
    "preparation step for a supervised learning task (e.g., classification), so you can simply use grid search to\n",
    "select the kernel and hyperparameters that lead to the best performance on that task. For example, the\n",
    "following code creates a two-step pipeline, first reducing dimensionality to two dimensions using kPCA,\n",
    "then applying Logistic Regression for classification. Then it uses GridSearchCV to find the best kernel\n",
    "and gamma value for kPCA in order to get the best classification accuracy at the end of the pipeline:\n",
    "We can list three kernel type model for PCA : \n",
    "- Linear Kernel: it is like using normal PCA\n",
    "-  RBF Kernel ( Radian Biased Function)\n",
    "- Sigmoid Kernel (Logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf = Pipeline([\n",
    "(\"kpca\", KernelPCA(n_components=2)),\n",
    "(\"log_reg\", LogisticRegression())\n",
    "])\n",
    "param_grid = [{\n",
    "\"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
    "\"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
    "#grid_search.fit(X, y)\n",
    "#print(grid_search.best_params_)\n",
    "#  {'kpca__gamma': 0.043333333333333335, 'kpca__kernel': 'rbf'}\n",
    "# Now use gamma to do your KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.0433,\n",
    "fit_inverse_transform=True)\n",
    "X_reduced = rbf_pca.fit_transform(X)\n",
    "X_preimage = rbf_pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be wondering how to perform this **reconstruction**. One solution is to train a supervised\n",
    "regression model, with the projected instances as the training set and the original instances as the targets.\n",
    "Scikit-Learn will do this automatically if you set **fit_inverse_transform=True**, as shown in the\n",
    "following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.0433,\n",
    "fit_inverse_transform=True)\n",
    "X_reduced = rbf_pca.fit_transform(X)\n",
    "X_preimage = rbf_pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, fit_inverse_transform=False and KernelPCA has no inverse_transform() method. This method only gets\n",
    "created when you set fit_inverse_transform=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83599220256337026"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can then compute the reconstruction pre-image error:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(X, X_preimage)\n",
    "# 32.786308795766132"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use grid search with cross-validation to find the kernel and hyperparameters that minimize\n",
    "this pre-image reconstruction error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLE\n",
    "**Locally Linear Embedding** (**LLE**) is another very powerful **nonlinear dimensionality reduction**\n",
    "(**NLDR**) technique. It is a Manifold Learning technique that does not rely on projections like the previous algorithms. In a nutshell, LLE works by first measuring how each training instance linearly relates to its closest neighbors (c.n.), and then looking for a low-dimensional representation of the training set where these local relationships are best preserved (more details shortly).\n",
    "\n",
    "This makes it particularly good at\n",
    "unrolling twisted manifolds, especially when there is not too much noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try it with the swiss roll data\n",
    "#from sklearn.datasets import make_swiss_roll\n",
    "#X=make_swiss_roll(100)\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=8)\n",
    "#X_reduced = lle.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Dimensionality Reduction Techniques\n",
    "There are many other dimensionality reduction techniques, several of which are available in Scikit-Learn.\n",
    "Here are some of the most popular:\n",
    "- **Multidimensional Scaling (MDS)** reduces dimensionality while trying to preserve the distances between the instances. \n",
    "- **Isomap** creates a graph by connecting each instance to its nearest neighbors, then reduces dimensionality while trying to preserve the geodesic distances between the instances. \n",
    "- **t-Distributed Stochastic Neighbor Embedding (t-SNE)** reduces dimensionality while trying to keep similar instances close and dissimilar instances apart. It is mostly used for visualization, in particular to visualize clusters of instances in high-dimensional space (e.g., to visualize the MNIST\n",
    "images in 2D).\n",
    "- **Linear Discriminant Analysis (LDA)** is actually a classification algorithm, but during training it\n",
    "learns the most discriminative axes between the classes, and these axes can then be used to define a\n",
    "hyperplane onto which to project the data. The benefit is that the projection will keep classes as far\n",
    "apart as possible, so LDA is a good technique to reduce dimensionality before running another classification algorithm such as an SVM classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
